# ğŸ“˜ SOTA Implementation

A collection of research paper implementations mainly for learning purpose â€”  
sometimes just the architecture, sometimes full projects.

I also share explanations via:

- ğŸ“ [[`Blog`](https://medium.com/@povashraful)] 
- ğŸ¥ [[`YouTube`](https://www.youtube.com/@povashraful)] 



---

## ğŸ” What's Inside

Each folder typically includes:

- ğŸ“„ Paper reference  
- ğŸ§± Model/code  
- ğŸ“ Blog link (if any)  
- ğŸ¬ Video walkthrough (if any)

---

## âœ… Examples

- **AlexNet** â€“  [[`Code`](https://github.com/povashraful/Research_paper_implementation/tree/main/AlexNet)] [[`Orginal Paper`](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)] <br>

- **VGGNet-16** â€“  [[`Code`](https://github.com/povashraful/Research_paper_implementation/blob/main/Implementing_VGGNet(16)_using_PyTorch.ipynb)] [[`Orginal Paper`](https://arxiv.org/abs/1409.1556)] <br>

- **U-Net** â€“  [[`Code`](https://github.com/povashraful/Research_paper_implementation/blob/main/Implementing_U_Net.ipynb)] [[`Orginal Paper`](https://arxiv.org/abs/1505.04597)] <br>

- **Attention is all your need (Transformers)** â€“  [[`Code`](https://github.com/povashraful/sota_implementation/tree/main/Attention%20is%20all%20you%20need%20(Transformers))] [[`Orginal Paper`](https://arxiv.org/abs/1706.03762)] Implementation video: (coming soon) <br>

- **Simple LLM Tokenizer from scratch** - [[`Code`](https://github.com/povashraful/sota_implementation/blob/main/Attention%20is%20all%20you%20need%20(Transformers)/simple_tokenizer_from_scratch.ipynb)]<br>
-  **Byte Pair Encoding from scratch** -   <br>
- **BackPropagation from scratch** [[``]()]   [[``]()] <<br>
- **Simple Gradient Descent (for maths)** â€“  [[`Code`](https://github.com/povashraful/sota_implementation/blob/main/Fundamental%20Deep%20Learning%20%26%20Optimization%20Algorithms/Simple_Gradient_Descent.ipynb)] <br>

-   [Code](#) | [Blog](#) | [YT](#)  


---

## ğŸ“¬ Contributions

Suggestions & improvements are welcome!

---

## ğŸ“„ License

MIT











