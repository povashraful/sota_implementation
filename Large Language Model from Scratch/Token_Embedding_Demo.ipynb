{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGXBsz5KXTuRuI9b7EGlCQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/povashraful/SOTA-Implementation/blob/main/Large%20Language%20Model%20from%20Scratch/Token_Embedding_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec - by Google"
      ],
      "metadata": {
        "id": "zFN6vCOZGEM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec (pre-trained trained on a part of the Google News dataset (about 100 billion words). The model contains 3-- dimensional vectors for 3 million words and phrases. ) - source Hugging Face"
      ],
      "metadata": {
        "id": "j3uFREtiGI80"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxpODdzBFmNz",
        "outputId": "80fd8bb9-ec63-434c-da47-a9afdab24d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "rDtyftZXFzhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNKGFVSzHZ4w",
        "outputId": "b7d30bea-a249-4f58-98eb-e6d303208713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of a word -represented as a vector"
      ],
      "metadata": {
        "id": "mRncC-6FIV3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let us now see how the vector embedding of a word looks like\n",
        "\n",
        "word_vectors = model\n",
        "\n",
        "\n",
        "# Example: Accessing the vector for the word 'computer'\n",
        "print(word_vectors['computer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmnBBsFBKQU7",
        "outputId": "115666ab-fa12-4c1c-db4d-b83eea576bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
            " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
            "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
            "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
            " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
            " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
            "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
            "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
            " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
            " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
            " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
            "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
            " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
            "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
            "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
            "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
            " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
            " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
            "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
            "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
            "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
            "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
            " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
            " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
            "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
            "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
            " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
            "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
            " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
            " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
            " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
            " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
            "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
            " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
            "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
            "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
            " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
            " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
            " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
            " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
            " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
            " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
            " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
            " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
            "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
            " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
            "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
            "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
            " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
            "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
            " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
            "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
            " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
            " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
            " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
            " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
            " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
            " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
            " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
            "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
            "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
            " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
            "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
            " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
            "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
            " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
            "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
            " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
            " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
            " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
            "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
            "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
            "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
            "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
            "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors['computer'].shape)\n",
        "\n",
        "# trying to how many dimensions do we have"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xoijqkUJlsq",
        "outputId": "ddb054dd-ea10-4b7c-d3ae-0c84b333a923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now see if vector embedding captures semantic meaning or not!"
      ],
      "metadata": {
        "id": "S5CYDtPLPkEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "King + Woman - Man = ?"
      ],
      "metadata": {
        "id": "IfFqAujKPuMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of using most_similar\n",
        "\n",
        "results = word_vectors.most_similar(\n",
        "    positive=['king', 'woman'],\n",
        "    negative=['man'],\n",
        "    topn=18\n",
        ")\n",
        "\n",
        "print(f\"{'Word':<25} {'Similarity':>10}\")\n",
        "print(\"-\" * 37)\n",
        "\n",
        "for word, score in results:\n",
        "    print(f\"{word:<25} {score:>10.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXhlMCKzPr05",
        "outputId": "39b138d0-d71b-4b2f-9add-56329dc17c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                      Similarity\n",
            "-------------------------------------\n",
            "queen                         0.7118\n",
            "monarch                       0.6190\n",
            "princess                      0.5902\n",
            "crown_prince                  0.5499\n",
            "prince                        0.5377\n",
            "kings                         0.5237\n",
            "Queen_Consort                 0.5236\n",
            "queens                        0.5181\n",
            "sultan                        0.5099\n",
            "monarchy                      0.5087\n",
            "royal_palace                  0.5087\n",
            "throne                        0.5006\n",
            "royal                         0.4938\n",
            "Princess_Sikhanyiso           0.4937\n",
            "ruler                         0.4909\n",
            "empress                       0.4888\n",
            "Prince_Paras                  0.4833\n",
            "princes                       0.4811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let us now see how the vector embedding of a word looks like\n",
        "\n",
        "word_vectors2 = model\n",
        "\n",
        "\n",
        "# Example: Accessing the vector for the word 'computer'\n",
        "print(word_vectors['Human'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBmrMic0RWaY",
        "outputId": "542199a5-4dcb-4bd2-cf95-790de10608c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.10839844e-01  3.44238281e-02  4.39453125e-01  1.74804688e-01\n",
            " -1.37695312e-01  2.80761719e-02  7.76367188e-02  8.64257812e-02\n",
            "  9.70458984e-03  1.56250000e-01  6.05468750e-02  1.94335938e-01\n",
            "  7.27539062e-02 -1.90429688e-01  3.22265625e-02 -2.10937500e-01\n",
            "  1.91406250e-01  8.98437500e-02 -2.37304688e-01  2.23632812e-01\n",
            " -1.14746094e-01 -4.63867188e-02  7.08007812e-02  1.83593750e-01\n",
            "  7.71484375e-02 -1.92382812e-01 -2.51953125e-01 -4.00390625e-02\n",
            "  3.47656250e-01 -2.46093750e-01 -3.57421875e-01  1.53320312e-01\n",
            " -1.27929688e-01 -1.30859375e-01 -3.67187500e-01  1.07421875e-01\n",
            " -9.86328125e-02  1.49414062e-01 -1.62109375e-01 -6.83593750e-02\n",
            " -1.61743164e-03  2.65625000e-01 -2.09960938e-01  4.96093750e-01\n",
            " -1.72851562e-01  2.35351562e-01 -1.18164062e-01  2.67578125e-01\n",
            " -4.05273438e-02  8.30078125e-02 -1.19628906e-01 -6.59179688e-02\n",
            " -3.26171875e-01 -2.95639038e-04  4.76074219e-03 -5.17578125e-02\n",
            " -1.19140625e-01 -4.14062500e-01 -3.41796875e-02  3.06640625e-01\n",
            "  5.41992188e-02  1.52343750e-01 -1.73339844e-02  1.79687500e-01\n",
            " -6.44531250e-02 -1.41601562e-01  1.29882812e-01  9.37500000e-02\n",
            " -1.42822266e-02 -2.33398438e-01 -7.51953125e-02 -9.32617188e-02\n",
            " -4.27246094e-02 -5.92041016e-03 -2.78320312e-02 -2.15820312e-01\n",
            "  3.73046875e-01 -1.31835938e-01 -7.42187500e-02  9.46044922e-03\n",
            "  5.66406250e-02  1.17675781e-01  1.97265625e-01  9.61914062e-02\n",
            " -7.71484375e-02 -3.20312500e-01  4.94384766e-03  3.27148438e-02\n",
            " -2.30468750e-01  3.26171875e-01 -5.34667969e-02  1.87500000e-01\n",
            "  4.41894531e-02 -1.14257812e-01  4.83398438e-02  7.27539062e-02\n",
            "  3.73046875e-01  5.95092773e-04  4.29687500e-02 -2.00195312e-01\n",
            "  6.00585938e-02 -1.42578125e-01 -4.02832031e-02 -2.33398438e-01\n",
            "  3.33984375e-01  4.90234375e-01  7.17773438e-02 -2.73437500e-01\n",
            " -5.73730469e-02 -5.88378906e-02 -4.63867188e-02 -2.65625000e-01\n",
            "  1.21582031e-01  1.02050781e-01 -1.83593750e-01 -2.67578125e-01\n",
            " -2.53906250e-01  2.61718750e-01  1.96289062e-01 -1.50756836e-02\n",
            "  5.59082031e-02 -1.58203125e-01 -3.98437500e-01  1.04980469e-01\n",
            " -1.88476562e-01 -7.03125000e-02 -1.93359375e-01 -7.62939453e-03\n",
            "  1.66015625e-01 -2.20703125e-01  2.89062500e-01 -2.47070312e-01\n",
            " -3.04687500e-01  7.87353516e-03 -3.82812500e-01 -1.66992188e-01\n",
            "  1.74804688e-01  3.14941406e-02  2.29492188e-01 -1.23535156e-01\n",
            "  2.49023438e-01 -4.83398438e-02 -6.98242188e-02 -1.25732422e-02\n",
            " -9.52148438e-02  2.22656250e-01  3.16406250e-01  3.47656250e-01\n",
            "  1.89453125e-01  1.56402588e-04  3.00781250e-01  1.15966797e-02\n",
            " -2.31445312e-01  2.81250000e-01  3.94531250e-01 -2.20703125e-01\n",
            " -1.21582031e-01 -2.13867188e-01  3.30078125e-01 -2.87109375e-01\n",
            "  1.91650391e-02 -5.07812500e-01  6.12792969e-02  4.00390625e-02\n",
            " -1.33789062e-01  7.61718750e-02  6.73828125e-02  1.28906250e-01\n",
            " -6.54296875e-02 -1.00097656e-01 -3.80859375e-02 -1.36718750e-01\n",
            "  2.28515625e-01  1.92382812e-01  3.55468750e-01  2.21679688e-01\n",
            " -1.32812500e-01 -2.23632812e-01 -9.42382812e-02 -3.75000000e-01\n",
            " -7.04956055e-03  2.58789062e-02  2.36328125e-01 -2.28515625e-01\n",
            " -3.96484375e-01  4.90722656e-02  1.19140625e-01  8.15429688e-02\n",
            " -1.12304688e-01  1.15234375e-01  6.19506836e-03  4.83398438e-02\n",
            " -1.29882812e-01 -1.60156250e-01 -3.78906250e-01 -1.01074219e-01\n",
            " -3.93066406e-02 -1.65039062e-01  3.94531250e-01 -2.05078125e-02\n",
            "  1.97265625e-01  2.24609375e-01 -4.78515625e-01 -1.79687500e-01\n",
            " -1.59179688e-01 -1.82617188e-01 -4.17968750e-01  2.62451172e-02\n",
            " -2.63671875e-01 -1.17187500e-01 -3.20312500e-01  4.12597656e-02\n",
            "  3.83300781e-02 -5.88378906e-02 -1.55273438e-01  2.25830078e-02\n",
            "  3.37890625e-01 -1.02050781e-01  2.15820312e-01  1.77734375e-01\n",
            "  2.44140625e-01  1.15722656e-01  2.62451172e-02 -2.24609375e-01\n",
            "  2.15820312e-01 -2.77343750e-01  2.67578125e-01 -8.25195312e-02\n",
            " -7.37304688e-02  7.76367188e-02  4.25781250e-01  3.16406250e-01\n",
            " -9.76562500e-02  8.78906250e-02 -1.99218750e-01 -1.81640625e-01\n",
            "  7.12890625e-02 -9.91210938e-02 -4.51660156e-02 -1.58203125e-01\n",
            "  7.22656250e-02 -3.20312500e-01  1.24023438e-01 -5.70312500e-01\n",
            "  4.70703125e-01 -3.00292969e-02  4.98046875e-02  4.88281250e-04\n",
            " -4.16015625e-01 -1.37695312e-01 -1.20117188e-01  7.71484375e-02\n",
            " -1.18652344e-01 -1.74804688e-01  7.78198242e-03  1.01562500e-01\n",
            " -6.65283203e-03  3.04687500e-01  6.83593750e-02 -9.57031250e-02\n",
            " -1.92382812e-01  1.68945312e-01 -4.10156250e-02 -1.30859375e-01\n",
            " -1.08398438e-01 -2.00195312e-02 -4.84375000e-01  2.71606445e-03\n",
            " -1.26953125e-01  1.65039062e-01  1.22070312e-01  1.08398438e-01\n",
            " -2.27539062e-01 -9.57031250e-02 -1.83593750e-01  1.90734863e-04\n",
            " -2.08007812e-01  7.37304688e-02  4.58984375e-02 -2.09960938e-01\n",
            " -1.41601562e-01 -2.02148438e-01 -6.64062500e-02  1.79687500e-01\n",
            "  8.15429688e-02 -1.69921875e-01 -8.88671875e-02  1.74560547e-02\n",
            "  4.61425781e-02  2.59765625e-01  7.71484375e-02 -2.13867188e-01\n",
            " -6.95312500e-01  3.39843750e-01  1.18652344e-01 -3.68652344e-02\n",
            "  4.02832031e-02  2.38037109e-02  6.49414062e-02  1.62109375e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of using most_similar\n",
        "\n",
        "results = word_vectors.most_similar(\n",
        "    positive=['Ape', 'Mon'],\n",
        "    negative=['Spirit'],\n",
        "    topn=18\n",
        ")\n",
        "\n",
        "print(f\"{'Word':<25} {'Similarity':>10}\")\n",
        "print(\"-\" * 37)\n",
        "\n",
        "for word, score in results:\n",
        "    print(f\"{word:<25} {score:>10.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxU1Ers7SRiQ",
        "outputId": "34cb387b-b243-475b-97e8-7bcf9098e086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                      Similarity\n",
            "-------------------------------------\n",
            "Thu                           0.4896\n",
            "Tue                           0.4844\n",
            "Fri                           0.4718\n",
            "Wed                           0.4688\n",
            "Sat                           0.4646\n",
            "Thur                          0.4286\n",
            "marx                          0.4039\n",
            "Jei                           0.4007\n",
            "Art_Gallerie                  0.3979\n",
            "By_Thorin_Klosowski           0.3880\n",
            "By_Devin_Desjarlais           0.3858\n",
            "By_Ily_Goyanes                0.3823\n",
            "Rebecca_Haithcoat             0.3797\n",
            "mond                          0.3786\n",
            "Politicks                     0.3780\n",
            "白                             0.3776\n",
            "Michael_Colyar                0.3772\n",
            "Htaw                          0.3770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now check the similarity b/w a few pair of words\n"
      ],
      "metadata": {
        "id": "o5WRFKnxJ8hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of calculating similarity\n",
        "print(word_vectors.similarity('woman', 'man'))\n",
        "print(word_vectors.similarity('king','queen'))\n",
        "print(word_vectors.similarity('uncle','aunt'))\n",
        "print(word_vectors.similarity('boy','girl'))\n",
        "print(word_vectors.similarity('nephew','niece'))\n",
        "print(word_vectors.similarity('paper','water'))\n",
        "print(word_vectors.similarity('airplane','jet'))\n",
        "print(word_vectors.similarity('duck','bird'))\n",
        "# we can give different words to try it out\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7djJ3SjBJ7sx",
        "outputId": "5343b1b4-be11-4c20-a19d-1426893ea91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.76640123\n",
            "0.6510957\n",
            "0.7643474\n",
            "0.8543272\n",
            "0.7594367\n",
            "0.11408084\n",
            "0.7161611\n",
            "0.5125556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most similar words from a given word"
      ],
      "metadata": {
        "id": "evVbInhzOsDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors.most_similar(\"airplane\", topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqN0zLfqOeFN",
        "outputId": "dc3ad4c3-26f9-458c-82f6-0d2e55760b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('plane', 0.8348401784896851), ('airplanes', 0.7777001261711121), ('aircraft', 0.76496422290802), ('planes', 0.7335887551307678), ('jet', 0.7161610722541809)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us see the vector similarity"
      ],
      "metadata": {
        "id": "Zdf_TNvDOwid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "magnitude = the great size or extent of something or size."
      ],
      "metadata": {
        "id": "sYFvxbFmTqdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# words to compare\n",
        "\n",
        "word1 = 'man'\n",
        "word2 = 'woman'\n",
        "\n",
        "word3 = 'semiconductor'\n",
        "word4 = 'earthworm'\n",
        "\n",
        "word5 = 'nephew'\n",
        "word6 = 'niece'\n",
        "\n",
        "word7 = 'pirate'\n",
        "word8  = 'mercenary'\n",
        "\n",
        "# Calculate the vector difference\n",
        "vector_difference1 = model[word1] - model[word2]\n",
        "vector_difference2 = model[word3] - model[word4]\n",
        "vector_difference3 = model[word5] - model[word6]\n",
        "vector_difference4 = model[word7] - model[word8]\n",
        "\n",
        "\n",
        "# Calculate the magnitutde of the vector difference\n",
        "\n",
        "magnitude_of_difference1 = np.linalg.norm(vector_difference1)\n",
        "magnitude_of_difference2 = np.linalg.norm(vector_difference2)\n",
        "magnitude_of_difference3 = np.linalg.norm(vector_difference3)\n",
        "magnitude_of_difference4 = np.linalg.norm(vector_difference4)\n",
        "\n",
        "\n",
        "# Print the magnitude of the difference\n",
        "\n",
        "print(\n",
        "    \"The magnitude of the difference between '{}' and '{}' is {:.2f}\"\n",
        "    .format(word1, word2, magnitude_of_difference1)\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"The magnitude of the difference between '{}' and '{}' is {:.2f}\"\n",
        "    .format(word3, word4, magnitude_of_difference2)\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"The magnitude of the difference between '{}' and '{}' is {:.2f}\"\n",
        "    .format(word5, word6, magnitude_of_difference3)\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"The magnitude of the difference between '{}' and '{}' is {:.2f}\"\n",
        "    .format(word7, word8, magnitude_of_difference4)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXTRmqgPO2G2",
        "outputId": "88d192b5-daea-439d-e693-6f465fe8caa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The magnitude of the difference between 'man' and 'woman' is 1.73\n",
            "The magnitude of the difference between 'semiconductor' and 'earthworm' is 5.67\n",
            "The magnitude of the difference between 'nephew' and 'niece' is 1.96\n",
            "The magnitude of the difference between 'pirate' and 'mercenary' is 3.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "dPNAQhbiHWC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([11, 45, 31, 33, 90, 110, 220])\n"
      ],
      "metadata": {
        "id": "L0vpsbmoHOz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 7\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "nAaCeAipHRRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gg = embedding_layer.weight\n",
        "\n",
        "print(gg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOvDlyqqHjt5",
        "outputId": "8a1595f0-3de5-425b-8d00-183ab138574e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196],\n",
            "        [-0.3792,  0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951],\n",
            "        [ 0.4954,  0.2692, -0.0770, -1.0205, -0.1690,  0.9178,  1.5810],\n",
            "        [ 1.3010,  1.2753, -0.2010,  0.4965, -1.5723, -0.4845, -2.0929],\n",
            "        [-0.8199, -0.4210, -0.9620,  1.2825,  0.8768,  1.6221, -0.9887],\n",
            "        [-1.7018, -0.7498, -1.1285,  0.4135,  0.2892,  2.2473, -0.8036]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gg[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqtvAGciH6ib",
        "outputId": "086cd675-577c-4353-cf6a-8df6f6888982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.3010,  1.2753, -0.2010,  0.4965, -1.5723, -0.4845, -2.0929],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gg[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e13IzCvzMhjm",
        "outputId": "13db5e46-30ab-4755-c1f0-09d02c24f0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(input_ids))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Lwmts5zH_eX",
        "outputId": "b730ba93-6095-4627-8d9e-53cad9ab637b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4954,  0.2692, -0.0770, -1.0205, -0.1690,  0.9178,  1.5810],\n",
            "        [ 1.3010,  1.2753, -0.2010,  0.4965, -1.5723, -0.4845, -2.0929],\n",
            "        [-1.7018, -0.7498, -1.1285,  0.4135,  0.2892,  2.2473, -0.8036],\n",
            "        [-0.3792,  0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    }
  ]
}